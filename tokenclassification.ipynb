{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\nimport torch\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\nimport os\n\n# –û—Ç–∫–ª—é—á–∞–µ–º W&B\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏\ntokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\", add_prefix_space=True)\nmodel = AutoModelForTokenClassification.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\", num_labels=2)\n\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        labels = self.labels[idx]\n        \n        tokenized_inputs = self.tokenizer(\n            text,\n            max_length=self.max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_tensors=\"pt\",\n            is_split_into_words=True\n        )\n        \n        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫\n        label_ids = [-100] * len(tokenized_inputs[\"input_ids\"][0])\n        for i, label in enumerate(labels[:self.max_length]):\n            label_ids[i] = label\n\n        tokenized_inputs[\"labels\"] = torch.tensor(label_ids)\n        return {key: val.squeeze() for key, val in tokenized_inputs.items()}\n\n# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö\ntexts = [\n    [\"–≠—Ç–æ\", \"–ø–µ—Ä–≤—ã–π\", \"—Ç–µ–∫—Å—Ç\", \".\", \"–°–ª–µ–¥—É—é—â–∏–π\", \"—Ç–µ–∫—Å—Ç\", \"–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è\", \"—Å\", \"—ç—Ç–æ–≥–æ\", \"—Å–ª–æ–≤–∞\", \".\"],\n    [\"–ù–∞—á–∞–ª–æ\", \"–Ω–æ–≤–æ–≥–æ\", \"—Ç–µ–∫—Å—Ç–∞\", \".\", \"–ò\", \"–µ—â—ë\", \"–æ–¥–∏–Ω\", \"–ø—Ä–∏–º–µ—Ä\", \".\"]\n]\nlabels = [\n    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n    [1, 0, 0, 0, 1, 0, 0, 0]\n]\n\n# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\ntrain_dataset = TextDataset(train_texts, train_labels, tokenizer)\nval_dataset = TextDataset(val_texts, val_labels, tokenizer)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",  # –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–π logging_steps —à–∞–≥\n    evaluation_strategy=\"epoch\",  # –û—Ü–µ–Ω–∫–∞ –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n    save_steps=100,\n    logging_steps=10,\n    logging_first_step=True, \n)\n\n\n# –§—É–Ω–∫—Ü–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫\ndef compute_metrics(pred):\n    labels = pred.label_ids.flatten()\n    preds = np.argmax(pred.predictions, axis=2).flatten()\n\n    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (–±–µ–∑ -100)\n    valid_indices = labels != -100\n    labels = labels[valid_indices]\n    preds = preds[valid_indices]\n\n    accuracy = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n    return {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }\n\n# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Trainer –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)\n\n# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\ntrainer.train()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-14T06:59:58.609693Z","iopub.execute_input":"2024-11-14T06:59:58.610582Z","iopub.status.idle":"2024-11-14T07:00:18.453794Z","shell.execute_reply.started":"2024-11-14T06:59:58.610531Z","shell.execute_reply":"2024-11-14T07:00:18.452645Z"}},"outputs":[{"name":"stderr","text":"Some weights of GPT2ForTokenClassification were not initialized from the model checkpoint at sberbank-ai/rugpt3small_based_on_gpt2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3/3 00:13, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.727400</td>\n      <td>2.648852</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.727400</td>\n      <td>1.430057</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.727400</td>\n      <td>0.982530</td>\n      <td>0.750000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3, training_loss=0.7238843639691671, metrics={'train_runtime': 17.2573, 'train_samples_per_second': 0.174, 'train_steps_per_second': 0.174, 'total_flos': 783890270208.0, 'train_loss': 0.7238843639691671, 'epoch': 3.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}